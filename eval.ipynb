{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import json\n",
    "from skyview_dataset import skyview_data\n",
    "\n",
    "api_key = \"\"\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "def encode_image(folder, image_filename):\n",
    "    image_path = os.path.join(\"Aerial_Landscapes\", folder, image_filename)\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "\n",
    "\n",
    "system_message = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": [\n",
    "        {\n",
    "        \"type\": \"text\",\n",
    "        \"text\": \"\"\"You are a helpful vision assistant that is going to help me understand the terrains of landscape images. The user wants to understand whether there is a place in the image that someone could land a small airplane. So being descriptive with the image given this context is crucial. \n",
    "            If there is no possible emergency landing areas then this is also something to consider. Keep your output to 5 sentences, with the last sentence giving a score on feasibility of landing an airplane. Specifically, the first four sentences will describe the landscape and the pros and cons of it given this emergency landing scenario. \n",
    "            The last sentence you should give a score out of 100 for whether the plane can land somewhere in the image or not, and the chance of survival if landed. 0 would indicate there is no survival chances, such as in mountainous areas or deep oceans and 100 would indicate an airport which is really safe to land on. \n",
    "            Note: a small airplane is 26 feet long with a wingspan of 36 feet and a cabin height of roughly 4 feet. Here is an example response: \n",
    "            1) The landscape shows a winding river surrounded by uneven terrain, with visible vegetation and some open areas.\n",
    "            2) The riverbanks appear to have patches of flat land, but the irregularity and potential wetness of the soil pose risks.\n",
    "            3) Vegetation is scattered, which could obstruct a small plane's landing, and the lack of a consistent open stretch limits options for a safe touchdown.\n",
    "            4) While the river itself is unsuitable for landing, the narrow flat stretches near it may offer limited possibilities in an extreme emergency, though precision is critical.\n",
    "            Score: 35/100 - The terrain presents significant challenges for landing, with survival chances depending on precision and the condition of the nearby flat areas.\"\"\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "for datum in skyview_data:\n",
    "    base64_image = encode_image(datum[\"folder\"], datum[\"image\"])\n",
    "    \n",
    "    user_content = [\n",
    "        {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\n",
    "                \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Make the API call\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            system_message,\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_content\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    answer = response.choices[0].message.content\n",
    "\n",
    "    datum[\"gpt\"] = answer\n",
    "\n",
    "with open(\"skyview_data_gpt.json\", \"w\") as outfile:\n",
    "    json.dump(skyview_data, outfile, indent=2)\n",
    "\n",
    "# #TEST\n",
    "# for d in skyview_data[:5]:  \n",
    "#     print(f\"ID: {d['id']}, Folder: {d['folder']}, Image: {d['image']}\")\n",
    "#     print(\"GPT Analysis:\", d[\"gpt\"])\n",
    "#     print(\"---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALL LLAVA AND ASK GPT TO COMPARE SCORES AND STORE\n",
    "\n",
    "# Get data from the json\n",
    "data = []\n",
    "with open(\"skyview_data_gpt.json\", \"r\") as infile:\n",
    "    data = json.load(infile)  \n",
    "\n",
    "\n",
    "#TODO MAKE THIS MORE DESCRIPTVE, ASK TO GIVE SCORE out of 10 for effectiveness of both and explain data input and the format of data output\n",
    "new_system_message = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": [\n",
    "        {\n",
    "        \"type\": \"text\",\n",
    "        \"text\": \"\"\" You are going to help me judge between the following output for which is more descriptive given the following image.\n",
    "         Specifically, I want you to tell me which description more accurately describes the landscape. Additionally, each response will give score which determines how suitable this landscape would be an emergency landing for a small airplane.\n",
    "         Note: a small airplane is 26 feet long with a wingspan of 36 feet and a cabin height of roughly 4 feet.\n",
    "         With this score, a lower score would mean that this landscape is very dangerous for a emergency landing, and a high score would deem the landscape in the image to be super safe. An example of a super safe landscape is an airport and an example of a dangerous landscape is the deep ocean.\n",
    "         I want you to consider this score when deciding which response was the best.\n",
    "         Your input will be in the form of\n",
    "        ---\n",
    "         Resopnse1: {RESPONSE1}\n",
    "         Response2: {RESPONSE2}\n",
    "         {Image}\n",
    "        ---\n",
    "         Lastly, I want you to give your response in a certain format. This format will be in a json structure. Here is an exmample.\n",
    "         {\n",
    "            Response: # 1 or 2 depending on which response was better\n",
    "            ResponseDetail: # Put the full response here that you deemed better\n",
    "            Score: 79/100 # Score of the response that you said was better\n",
    "            Description: # Explain why this response was better than the other here\n",
    "\n",
    "        }\"\"\"\n",
    "        }\n",
    "        \n",
    "    ]\n",
    "}\n",
    "scores = {} # STORE SCORES LIKE GPT-> [(id,score)] LLAVA > [(id,score)]\n",
    "\n",
    "for datum in data:\n",
    "    base64_image = encode_image(datum[\"folder\"], datum[\"image\"])\n",
    "    \n",
    "    # CALL LLAVA HERE\n",
    "    llava_res = \"\"\n",
    "\n",
    "\n",
    "\n",
    "    user_content = [\n",
    "        \n",
    "        {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": f\"\"\"\n",
    "            RESPONSE 1: {llava_res}\n",
    "            RESPONSE 2: {data['gpt']}\"\"\"\n",
    "\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\n",
    "                \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Make the API call\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            new_system_message,\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_content\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    #PARSE RESPONSE, MAKE SURE GPT RESPONDS IN A WAY THAT IS EASIER TO RESPOND\n",
    "    gpt_score = 0\n",
    "    llava_score = 0\n",
    "\n",
    "    scores['gpt'].append((data['id'], gpt_score))\n",
    "    scores['llava'].append((data['id'], llava_score))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(\"skyview_eval_scores.json\", \"w\") as outfile:\n",
    "    json.dump(scores, outfile, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
